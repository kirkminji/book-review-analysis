{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML 기반 베스트셀러 예측 분석\n",
    "\n",
    "## 데이터 설명\n",
    "\n",
    "### 피처 구성\n",
    "| 그룹 | 피처 | 설명 |\n",
    "|------|------|------|\n",
    "| 카테고리 | category_1 ~ category_10 | 도서 카테고리 비율 |\n",
    "| 바이럴 | viral_index, viral_index_smoothed | 뉴스 기반 관심도 |\n",
    "| 카테고리×바이럴 | category_X_x_viral_index | 카테고리별 바이럴 영향 |\n",
    "| Prophet 예측 | prophet_forecast_X | 카테고리별 판매 예측값 (시차, 트렌드, 계절성 반영) × 카테고리 비율 |\n",
    "| 경제지표 | kospi, usd_krw, brent_oil 등 | 거시경제 변수 |\n",
    "\n",
    "### Prophet 예측값 특징\n",
    "- 각 카테고리의 최적 시차(lag)가 적용된 예측값\n",
    "- 해당 책의 카테고리 비율로 가중치 적용됨\n",
    "- 예: 주식투자 60% 책 → prophet_forecast_stock × 0.6\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import (f1_score, roc_auc_score, r2_score, mean_absolute_error,\n",
    "                             confusion_matrix, ConfusionMatrixDisplay, roc_curve)\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 이미지 저장 경로\n",
    "IMG_PATH = 'ml_image_v4'\n",
    "os.makedirs(IMG_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('books_ml_dataset_v4.csv')\n",
    "df['ymw'] = df['ymw'].astype(str)\n",
    "df = df.sort_values(['product_code', 'ymw']).reset_index(drop=True)\n",
    "\n",
    "print(f'데이터: {len(df):,}개')\n",
    "print(f'기간: {df[\"ymw\"].min()} ~ {df[\"ymw\"].max()}')\n",
    "print(f'고유 책 수: {df[\"product_code\"].nunique()}권')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 정의\n",
    "feature_cols = [c for c in df.columns if c not in ['product_code', 'ymw', 'y_sales_score']]\n",
    "\n",
    "print(f'피처 수: {len(feature_cols)}개')\n",
    "print(f'\\n[피처 그룹별 개수]')\n",
    "print(f'  category_: {len([c for c in feature_cols if c.startswith(\"category_\") and \"x_viral\" not in c])}개')\n",
    "print(f'  category_x_viral: {len([c for c in feature_cols if \"x_viral\" in c])}개')\n",
    "print(f'  prophet_forecast_: {len([c for c in feature_cols if c.startswith(\"prophet_\")])}개')\n",
    "print(f'  viral_index: {len([c for c in feature_cols if \"viral_index\" in c and \"x_\" not in c])}개')\n",
    "print(f'  기타 (경제지표 등): {len([c for c in feature_cols if not any(x in c for x in [\"category\", \"prophet\", \"viral_index\"])])}개')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split (Time-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based Split (시계열 데이터이므로 시간순 분할)\n",
    "df_sorted = df.sort_values('ymw').reset_index(drop=True)\n",
    "split_idx = int(len(df_sorted) * 0.8)\n",
    "\n",
    "train_data = df_sorted.iloc[:split_idx]\n",
    "test_data = df_sorted.iloc[split_idx:]\n",
    "\n",
    "X_train = train_data[feature_cols]\n",
    "X_test = test_data[feature_cols]\n",
    "y_train = train_data['y_sales_score']\n",
    "y_test = test_data['y_sales_score']\n",
    "y_train_class = (y_train > 0).astype(int)\n",
    "y_test_class = (y_test > 0).astype(int)\n",
    "\n",
    "print('[Time-based Split]')\n",
    "print(f'  Train: {train_data[\"ymw\"].min()} ~ {train_data[\"ymw\"].max()} ({len(train_data):,}개)')\n",
    "print(f'  Test:  {test_data[\"ymw\"].min()} ~ {test_data[\"ymw\"].max()} ({len(test_data):,}개)')\n",
    "print(f'\\n[타겟 분포]')\n",
    "print(f'  Train - 베스트셀러: {y_train_class.sum()} ({y_train_class.mean()*100:.1f}%)')\n",
    "print(f'  Test  - 베스트셀러: {y_test_class.sum()} ({y_test_class.mean()*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: 기존 피처만 사용한 예측\n",
    "\n",
    "바이럴 지수, Prophet 예측값, 카테고리 등 **외부 변수만으로** 베스트셀러를 예측할 수 있는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 기존 피처 상관관계 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟과 상관관계 분석\n",
    "y_full = df['y_sales_score']\n",
    "corr_list = []\n",
    "for col in feature_cols:\n",
    "    corr, pval = stats.pearsonr(df[col], y_full)\n",
    "    corr_list.append({'feature': col, 'corr': corr, 'abs_corr': abs(corr), 'pval': pval})\n",
    "\n",
    "corr_df = pd.DataFrame(corr_list).sort_values('abs_corr', ascending=False)\n",
    "\n",
    "print('[기존 피처 vs 타겟 상관관계 Top 15]')\n",
    "print('='*60)\n",
    "print(f'{\"순위\":<5}{\"피처\":<40}{\"r\":<10}{\"p-value\":<12}')\n",
    "print('-'*60)\n",
    "for i, (_, row) in enumerate(corr_df.head(15).iterrows()):\n",
    "    sig = '***' if row['pval'] < 0.001 else '**' if row['pval'] < 0.01 else '*' if row['pval'] < 0.05 else ''\n",
    "    print(f'{i+1:<5}{row[\"feature\"]:<40}{row[\"corr\"]:+.4f}    {row[\"pval\"]:.2e} {sig}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 시각화 (Top 15)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top15 = corr_df.head(15)\n",
    "colors = ['#e74c3c' if c > 0 else '#3498db' for c in top15['corr']]\n",
    "ax.barh(range(len(top15)), top15['corr'], color=colors)\n",
    "ax.set_yticks(range(len(top15)))\n",
    "ax.set_yticklabels(top15['feature'])\n",
    "ax.set_xlabel('상관계수 (r)')\n",
    "ax.set_title('기존 피처 vs 판매점수 상관관계 Top 15')\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}/01_feature_correlation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 기존 피처만으로 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 모델 정의\n",
    "reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n",
    "}\n",
    "\n",
    "needs_scaling = ['Linear Regression', 'Ridge']\n",
    "\n",
    "# 스케일링\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# 기존 피처만으로 학습\n",
    "base_results = []\n",
    "\n",
    "print('[기존 피처만 사용 - 회귀 모델 성능]')\n",
    "print('='*50)\n",
    "print(f'{\"모델\":<25}{\"R²\":<12}{\"MAE\":<12}')\n",
    "print('-'*50)\n",
    "\n",
    "for model_name, model in reg_models.items():\n",
    "    if model_name in needs_scaling:\n",
    "        X_tr, X_te = X_train_scaled, X_test_scaled\n",
    "    else:\n",
    "        X_tr, X_te = X_train, X_test\n",
    "    \n",
    "    reg = model.__class__(**model.get_params())\n",
    "    reg.fit(X_tr, y_train)\n",
    "    y_pred = np.maximum(reg.predict(X_te), 0)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    base_results.append({'model': model_name, 'r2': r2, 'mae': mae})\n",
    "    print(f'{model_name:<25}{r2:<12.4f}{mae:<12.4f}')\n",
    "\n",
    "base_results_df = pd.DataFrame(base_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 모델\n",
    "clf_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'LightGBM': lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42, verbose=-1),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, scale_pos_weight=3, random_state=42, verbosity=0),\n",
    "}\n",
    "\n",
    "base_clf_results = []\n",
    "\n",
    "print('\\n[기존 피처만 사용 - 분류 모델 성능]')\n",
    "print('='*60)\n",
    "print(f'{\"모델\":<25}{\"F1\":<12}{\"AUC\":<12}{\"Precision\":<12}')\n",
    "print('-'*60)\n",
    "\n",
    "for model_name, model in clf_models.items():\n",
    "    if model_name == 'Logistic Regression':\n",
    "        X_tr, X_te = X_train_scaled, X_test_scaled\n",
    "    else:\n",
    "        X_tr, X_te = X_train, X_test\n",
    "    \n",
    "    clf = model.__class__(**model.get_params())\n",
    "    clf.fit(X_tr, y_train_class)\n",
    "    y_pred_c = clf.predict(X_te)\n",
    "    y_prob = clf.predict_proba(X_te)[:, 1]\n",
    "    \n",
    "    f1 = f1_score(y_test_class, y_pred_c)\n",
    "    auc = roc_auc_score(y_test_class, y_prob)\n",
    "    prec = (y_pred_c[y_test_class == 1] == 1).mean() if y_pred_c.sum() > 0 else 0\n",
    "    \n",
    "    base_clf_results.append({'model': model_name, 'f1': f1, 'auc': auc})\n",
    "    print(f'{model_name:<25}{f1:<12.4f}{auc:<12.4f}{prec:<12.4f}')\n",
    "\n",
    "base_clf_results_df = pd.DataFrame(base_clf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 기존 피처 SHAP 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM으로 SHAP 분석\n",
    "reg_base = lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)\n",
    "reg_base.fit(X_train, y_train)\n",
    "\n",
    "explainer_base = shap.TreeExplainer(reg_base)\n",
    "shap_values_base = explainer_base.shap_values(X_test)\n",
    "\n",
    "# SHAP Summary Plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values_base, X_test, plot_type=\"bar\", show=False, max_display=20)\n",
    "plt.title('기존 피처 SHAP Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}/02_base_shap_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 중요도 테이블\n",
    "shap_base_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'mean_abs_shap': np.abs(shap_values_base).mean(axis=0)\n",
    "}).sort_values('mean_abs_shap', ascending=False)\n",
    "\n",
    "print('[기존 피처 SHAP 중요도 Top 10]')\n",
    "print('='*50)\n",
    "total_imp = shap_base_importance['mean_abs_shap'].sum()\n",
    "for i, (_, row) in enumerate(shap_base_importance.head(10).iterrows()):\n",
    "    pct = row['mean_abs_shap'] / total_imp * 100\n",
    "    print(f'{i+1}. {row[\"feature\"]:<35} {row[\"mean_abs_shap\"]:.4f} ({pct:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 기존 피처 예측 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 vs 실제\n",
    "y_pred_base = np.maximum(reg_base.predict(X_test), 0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# 산점도\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test, y_pred_base, alpha=0.4, s=20)\n",
    "ax1.plot([0, y_test.max()], [0, y_test.max()], 'r--', lw=2)\n",
    "ax1.set_xlabel('실제값')\n",
    "ax1.set_ylabel('예측값')\n",
    "ax1.set_title(f'기존 피처: 예측 vs 실제 (R² = {r2_score(y_test, y_pred_base):.4f})')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 잔차 분포\n",
    "ax2 = axes[1]\n",
    "residuals = y_test - y_pred_base\n",
    "ax2.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "ax2.set_xlabel('잔차')\n",
    "ax2.set_ylabel('빈도')\n",
    "ax2.set_title(f'잔차 분포 (MAE = {mean_absolute_error(y_test, y_pred_base):.4f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}/03_base_prediction_result.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Lag 피처 (전주 판매점수) 추가\n",
    "\n",
    "**y_lag1 (전주 판매점수)**를 추가했을 때 예측 성능이 어떻게 변하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lag 피처 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag 피처 생성\n",
    "df_lag = df.copy()\n",
    "for lag in [1, 2, 3, 4]:\n",
    "    df_lag[f'y_lag{lag}'] = df_lag.groupby('product_code')['y_sales_score'].shift(lag)\n",
    "\n",
    "print('[Lag 피처 결측치]')\n",
    "for lag in [1, 2, 3, 4]:\n",
    "    na = df_lag[f'y_lag{lag}'].isna().sum()\n",
    "    print(f'  y_lag{lag}: {na}개 ({na/len(df_lag)*100:.1f}%)')\n",
    "\n",
    "# 결측치 제거\n",
    "df_lag = df_lag.dropna(subset=['y_lag1']).reset_index(drop=True)\n",
    "print(f'\\n결측치 제거 후: {len(df_lag):,}개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag 피처 상관관계\n",
    "y_lag_full = df_lag['y_sales_score']\n",
    "\n",
    "print('[Lag 피처 vs 타겟 상관관계]')\n",
    "print('='*40)\n",
    "for lag in [1, 2, 3, 4]:\n",
    "    corr, pval = stats.pearsonr(df_lag[f'y_lag{lag}'].dropna(), df_lag.loc[df_lag[f'y_lag{lag}'].notna(), 'y_sales_score'])\n",
    "    print(f'  y_lag{lag}: r = {corr:.4f} (p < 0.001)')\n",
    "\n",
    "# 기존 피처 최고 상관관계와 비교\n",
    "best_base = corr_df.iloc[0]\n",
    "print(f'\\n[비교]')\n",
    "print(f'  기존 피처 최고: {best_base[\"feature\"]} (r = {best_base[\"corr\"]:.4f})')\n",
    "print(f'  y_lag1: r = 0.885 → 기존 최고 대비 {0.885/abs(best_base[\"corr\"]):.0f}배 강함')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_lag1 vs y 산점도\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(df_lag['y_lag1'], df_lag['y_sales_score'], alpha=0.3, s=10)\n",
    "ax.plot([0, df_lag['y_sales_score'].max()], [0, df_lag['y_sales_score'].max()], 'r--', lw=2)\n",
    "ax.set_xlabel('전주 판매점수 (y_lag1)')\n",
    "ax.set_ylabel('현재 판매점수')\n",
    "corr_lag1 = stats.pearsonr(df_lag['y_lag1'], df_lag['y_sales_score'])[0]\n",
    "ax.set_title(f'전주 vs 현재 판매점수 (r = {corr_lag1:.3f})')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}/04_lag1_correlation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Lag 피처 추가 후 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based Split (Lag 데이터)\n",
    "df_lag_sorted = df_lag.sort_values('ymw').reset_index(drop=True)\n",
    "split_idx_lag = int(len(df_lag_sorted) * 0.8)\n",
    "\n",
    "train_lag = df_lag_sorted.iloc[:split_idx_lag]\n",
    "test_lag = df_lag_sorted.iloc[split_idx_lag:]\n",
    "\n",
    "feature_cols_lag = feature_cols + ['y_lag1']\n",
    "\n",
    "X_train_lag = train_lag[feature_cols_lag]\n",
    "X_test_lag = test_lag[feature_cols_lag]\n",
    "y_train_lag = train_lag['y_sales_score']\n",
    "y_test_lag = test_lag['y_sales_score']\n",
    "y_train_lag_class = (y_train_lag > 0).astype(int)\n",
    "y_test_lag_class = (y_test_lag > 0).astype(int)\n",
    "\n",
    "# 스케일링\n",
    "scaler_lag = RobustScaler()\n",
    "X_train_lag_scaled = pd.DataFrame(scaler_lag.fit_transform(X_train_lag), columns=X_train_lag.columns, index=X_train_lag.index)\n",
    "X_test_lag_scaled = pd.DataFrame(scaler_lag.transform(X_test_lag), columns=X_test_lag.columns, index=X_test_lag.index)\n",
    "\n",
    "print('[Time-based Split (Lag 데이터)]')\n",
    "print(f'  Train: {len(train_lag):,}개')\n",
    "print(f'  Test:  {len(test_lag):,}개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_lag1 추가 후 회귀 모델 성능\n",
    "lag_results = []\n",
    "\n",
    "print('[y_lag1 추가 - 회귀 모델 성능]')\n",
    "print('='*50)\n",
    "print(f'{\"모델\":<25}{\"R²\":<12}{\"MAE\":<12}')\n",
    "print('-'*50)\n",
    "\n",
    "for model_name, model in reg_models.items():\n",
    "    if model_name in needs_scaling:\n",
    "        X_tr, X_te = X_train_lag_scaled, X_test_lag_scaled\n",
    "    else:\n",
    "        X_tr, X_te = X_train_lag, X_test_lag\n",
    "    \n",
    "    reg = model.__class__(**model.get_params())\n",
    "    reg.fit(X_tr, y_train_lag)\n",
    "    y_pred = np.maximum(reg.predict(X_te), 0)\n",
    "    \n",
    "    r2 = r2_score(y_test_lag, y_pred)\n",
    "    mae = mean_absolute_error(y_test_lag, y_pred)\n",
    "    \n",
    "    lag_results.append({'model': model_name, 'r2': r2, 'mae': mae})\n",
    "    print(f'{model_name:<25}{r2:<12.4f}{mae:<12.4f}')\n",
    "\n",
    "lag_results_df = pd.DataFrame(lag_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_lag1 추가 후 분류 모델 성능\n",
    "lag_clf_results = []\n",
    "\n",
    "print('\\n[y_lag1 추가 - 분류 모델 성능]')\n",
    "print('='*60)\n",
    "print(f'{\"모델\":<25}{\"F1\":<12}{\"AUC\":<12}')\n",
    "print('-'*60)\n",
    "\n",
    "for model_name, model in clf_models.items():\n",
    "    if model_name == 'Logistic Regression':\n",
    "        X_tr, X_te = X_train_lag_scaled, X_test_lag_scaled\n",
    "    else:\n",
    "        X_tr, X_te = X_train_lag, X_test_lag\n",
    "    \n",
    "    clf = model.__class__(**model.get_params())\n",
    "    clf.fit(X_tr, y_train_lag_class)\n",
    "    y_pred_c = clf.predict(X_te)\n",
    "    y_prob = clf.predict_proba(X_te)[:, 1]\n",
    "    \n",
    "    f1 = f1_score(y_test_lag_class, y_pred_c)\n",
    "    auc = roc_auc_score(y_test_lag_class, y_prob)\n",
    "    \n",
    "    lag_clf_results.append({'model': model_name, 'f1': f1, 'auc': auc})\n",
    "    print(f'{model_name:<25}{f1:<12.4f}{auc:<12.4f}')\n",
    "\n",
    "lag_clf_results_df = pd.DataFrame(lag_clf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Lag 피처 추가 후 SHAP 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM + y_lag1 SHAP 분석\n",
    "reg_lag = lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)\n",
    "reg_lag.fit(X_train_lag, y_train_lag)\n",
    "\n",
    "explainer_lag = shap.TreeExplainer(reg_lag)\n",
    "shap_values_lag = explainer_lag.shap_values(X_test_lag)\n",
    "\n",
    "# SHAP Summary Plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values_lag, X_test_lag, plot_type=\"bar\", show=False, max_display=20)\n",
    "plt.title('기존 피처 + y_lag1: SHAP Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}/05_lag_shap_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 중요도 테이블\n",
    "shap_lag_importance = pd.DataFrame({\n",
    "    'feature': feature_cols_lag,\n",
    "    'mean_abs_shap': np.abs(shap_values_lag).mean(axis=0)\n",
    "}).sort_values('mean_abs_shap', ascending=False)\n",
    "\n",
    "print('[y_lag1 추가 후 SHAP 중요도 Top 10]')\n",
    "print('='*55)\n",
    "total_imp_lag = shap_lag_importance['mean_abs_shap'].sum()\n",
    "for i, (_, row) in enumerate(shap_lag_importance.head(10).iterrows()):\n",
    "    pct = row['mean_abs_shap'] / total_imp_lag * 100\n",
    "    print(f'{i+1}. {row[\"feature\"]:<35} {row[\"mean_abs_shap\"]:.4f} ({pct:.1f}%)')\n",
    "\n",
    "# y_lag1 vs prophet 비교\n",
    "y_lag1_imp = shap_lag_importance[shap_lag_importance['feature'] == 'y_lag1']['mean_abs_shap'].values[0]\n",
    "prophet_imp = shap_lag_importance[shap_lag_importance['feature'].str.startswith('prophet_')]['mean_abs_shap'].sum()\n",
    "\n",
    "print(f'\\n[피처 그룹별 중요도]')\n",
    "print(f'  y_lag1: {y_lag1_imp/total_imp_lag*100:.1f}%')\n",
    "print(f'  prophet_forecast (10개): {prophet_imp/total_imp_lag*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Lag 피처 추가 후 예측 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 vs 실제\n",
    "y_pred_lag = np.maximum(reg_lag.predict(X_test_lag), 0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# 산점도\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test_lag, y_pred_lag, alpha=0.4, s=20)\n",
    "ax1.plot([0, y_test_lag.max()], [0, y_test_lag.max()], 'r--', lw=2)\n",
    "ax1.set_xlabel('실제값')\n",
    "ax1.set_ylabel('예측값')\n",
    "ax1.set_title(f'기존 + y_lag1: 예측 vs 실제 (R² = {r2_score(y_test_lag, y_pred_lag):.4f})')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 잔차 분포\n",
    "ax2 = axes[1]\n",
    "residuals_lag = y_test_lag - y_pred_lag\n",
    "ax2.hist(residuals_lag, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "ax2.set_xlabel('잔차')\n",
    "ax2.set_ylabel('빈도')\n",
    "ax2.set_title(f'잔차 분포 (MAE = {mean_absolute_error(y_test_lag, y_pred_lag):.4f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}/06_lag_prediction_result.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve & Confusion Matrix\n",
    "clf_lag = lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42, verbose=-1)\n",
    "clf_lag.fit(X_train_lag, y_train_lag_class)\n",
    "y_prob_lag = clf_lag.predict_proba(X_test_lag)[:, 1]\n",
    "y_pred_lag_class = clf_lag.predict(X_test_lag)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ROC Curve\n",
    "ax1 = axes[0]\n",
    "fpr, tpr, _ = roc_curve(y_test_lag_class, y_prob_lag)\n",
    "auc_score = roc_auc_score(y_test_lag_class, y_prob_lag)\n",
    "ax1.plot(fpr, tpr, 'b-', lw=2, label=f'LightGBM (AUC = {auc_score:.4f})')\n",
    "ax1.plot([0, 1], [0, 1], 'r--', lw=1)\n",
    "ax1.fill_between(fpr, tpr, alpha=0.2)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curve - 베스트셀러 진입 분류')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Confusion Matrix\n",
    "ax2 = axes[1]\n",
    "cm = confusion_matrix(y_test_lag_class, y_pred_lag_class)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['비진입', '베스트셀러'])\n",
    "disp.plot(ax=ax2, cmap='Blues', values_format='d')\n",
    "ax2.set_title(f'Confusion Matrix (F1 = {f1_score(y_test_lag_class, y_pred_lag_class):.4f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}/07_lag_roc_confusion.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: 성능 비교 및 인사이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 기존 피처 vs y_lag1 추가 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 성능 비교\n",
    "comparison = pd.merge(base_results_df, lag_results_df, on='model', suffixes=('_base', '_lag'))\n",
    "comparison['r2_improvement'] = comparison['r2_lag'] - comparison['r2_base']\n",
    "comparison['r2_improvement_pct'] = (comparison['r2_improvement'] / comparison['r2_base'].abs() * 100)\n",
    "\n",
    "print('[회귀 모델 성능 비교]')\n",
    "print('='*75)\n",
    "print(f'{\"모델\":<25}{\"기존 R²\":<12}{\"+ y_lag1 R²\":<12}{\"개선\":<12}{\"개선율\":<12}')\n",
    "print('-'*75)\n",
    "for _, row in comparison.iterrows():\n",
    "    print(f'{row[\"model\"]:<25}{row[\"r2_base\"]:<12.4f}{row[\"r2_lag\"]:<12.4f}{row[\"r2_improvement\"]:+.4f}      {row[\"r2_improvement_pct\"]:+.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 성능 비교\n",
    "comparison_clf = pd.merge(base_clf_results_df, lag_clf_results_df, on='model', suffixes=('_base', '_lag'))\n",
    "comparison_clf['f1_improvement'] = comparison_clf['f1_lag'] - comparison_clf['f1_base']\n",
    "\n",
    "print('\\n[분류 모델 성능 비교]')\n",
    "print('='*70)\n",
    "print(f'{\"모델\":<25}{\"기존 F1\":<12}{\"+ y_lag1 F1\":<12}{\"기존 AUC\":<12}{\"+ y_lag1 AUC\":<12}')\n",
    "print('-'*70)\n",
    "for _, row in comparison_clf.iterrows():\n",
    "    print(f'{row[\"model\"]:<25}{row[\"f1_base\"]:<12.4f}{row[\"f1_lag\"]:<12.4f}{row[\"auc_base\"]:<12.4f}{row[\"auc_lag\"]:<12.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# 회귀 R² 비교\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(comparison))\n",
    "width = 0.35\n",
    "bars1 = ax1.bar(x - width/2, comparison['r2_base'], width, label='기존 피처만', color='#3498db')\n",
    "bars2 = ax1.bar(x + width/2, comparison['r2_lag'], width, label='+ y_lag1', color='#e74c3c')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(comparison['model'], rotation=45, ha='right')\n",
    "ax1.set_ylabel('R²')\n",
    "ax1.set_title('회귀 모델: 기존 피처 vs + y_lag1')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# 분류 F1 비교\n",
    "ax2 = axes[1]\n",
    "bars1 = ax2.bar(x - width/2, comparison_clf['f1_base'], width, label='기존 피처만', color='#3498db')\n",
    "bars2 = ax2.bar(x + width/2, comparison_clf['f1_lag'], width, label='+ y_lag1', color='#e74c3c')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(comparison_clf['model'], rotation=45, ha='right')\n",
    "ax2.set_ylabel('F1 Score')\n",
    "ax2.set_title('분류 모델: 기존 피처 vs + y_lag1')\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}/08_performance_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 최종 결론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('최종 분석 결론')\n",
    "print('='*70)\n",
    "\n",
    "print('\\n[1. 기존 피처만 사용 시]')\n",
    "print(f'  - 회귀 R² (LightGBM): {base_results_df[base_results_df[\"model\"]==\"LightGBM\"][\"r2\"].values[0]:.4f}')\n",
    "print(f'  - 분류 F1 (LightGBM): {base_clf_results_df[base_clf_results_df[\"model\"]==\"LightGBM\"][\"f1\"].values[0]:.4f}')\n",
    "print(f'  - 해석: 바이럴 지수, Prophet 예측값으로는 예측 어려움')\n",
    "\n",
    "print('\\n[2. y_lag1 추가 시]')\n",
    "print(f'  - 회귀 R² (LightGBM): {lag_results_df[lag_results_df[\"model\"]==\"LightGBM\"][\"r2\"].values[0]:.4f}')\n",
    "print(f'  - 분류 F1 (LightGBM): {lag_clf_results_df[lag_clf_results_df[\"model\"]==\"LightGBM\"][\"f1\"].values[0]:.4f}')\n",
    "print(f'  - 개선율: R² +{comparison[comparison[\"model\"]==\"LightGBM\"][\"r2_improvement_pct\"].values[0]:.0f}%')\n",
    "\n",
    "print('\\n[3. SHAP 피처 중요도]')\n",
    "print(f'  - y_lag1: {y_lag1_imp/total_imp_lag*100:.1f}%')\n",
    "print(f'  - prophet_forecast (10개): {prophet_imp/total_imp_lag*100:.1f}%')\n",
    "\n",
    "print('\\n[4. 핵심 인사이트]')\n",
    "print('  - \"과거 성과가 미래 성과를 결정한다\" (베스트셀러 관성 효과)')\n",
    "print('  - 바이럴 지수, Prophet 예측값은 y_lag1 대비 기여도 미미')\n",
    "print('  - 전주에 베스트셀러였던 책은 이번 주에도 베스트셀러일 확률 높음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 이미지 목록\n",
    "print('\\n[저장된 시각화 파일]')\n",
    "for f in sorted(os.listdir(IMG_PATH)):\n",
    "    print(f'  {f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
